\documentclass{book}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}

\title{Randomized Algorithms}
\author{Jonathan Fragoso}

\begin{document}

\maketitle

%\begin{abstract}
%
%\end{abstract}

\tableofcontents

\chapter{Introduction}
\section{Randomized algorithms}
Algorithms that make random choices during their execution. In practice, a randomized program would use values generated by a random number generator to device the next step at several branches of its execution. 
\newline 
In some applications, randomized algorithms are significantly more efficient that the best known deterministic solutions. In addition to this fact, in most cases the randomized algorithms are also simpler and easier to program.
\newline
\newline
Because of the randomized approach, the efficiency is guaranteed only with some probability, but if the probability of error is sufficiently small, then the improvement in speed or memory requirements may well be worthwhile.
\section{Probabilistic analysis of algorithms}
Complexity theory tries to classify computation problems according to their computational complexity. Probabilistic analysis gives a theorical explanation for this phenomenon. If we think of the input as being randomly selected according to some probability distribution on the collection of all possible inputs, we are very likely to obtain a problem instance that is easy to solve, and instances that are hard to solve appear with relatively small probability. Thus, we can conclude saying that probabilistic analysis of algorithms is the method of studying how algorithms perform when the input is taken from a well-defined probabilistic space.

\chapter{Events and probabilities}
\section{Axioms of probability}
A probability space has three components:
\begin{enumerate}
\item Sample space ($\Omega$) which is the set of all possible outcomes of the random process modeled by the probability space. An element of $\Omega$ is called a simple or elementary event. 
\item Family of sets ($\mathcal{F}$) representing the allowable events, where each set in $\mathcal{F}$ is a subset of the sample space $\Omega$ 
\item probability function (Pr) : $\mathcal{F}$ $\rightarrow$ $\mathbb{R}$ that satisfies the following conditions:
\begin{enumerate}
\item for any event E, 0 $\leq$ Pr(E) $\leq$ 1;
\item Pr($\Omega$) = 1; and
\item for any finite or countably infinite sequence of pairwise mutually disjoint events $E_1, E_2, E_3,...,$
\newline
\begin{center}
$Pr \left(\bigcup_{i\geq1}^{} E_i\right) = \sum_{i\geq1}^{}Pr(E_i)$
\end{center} 
\end{enumerate}
\end{enumerate}
Suppose we roll two dice. If $E_1$ is the event that the first die is a 1 and $E_2$ is the event that the second die is a 1, then $E_1\cap E_2$ denotes the event that both dice are 1 while $E_1\cup E_2$ denotes the event that at least one of the two dices lands on 1. Similarly, we write $E_1-E_2$ for the occurence of an event that is in $E_!$ but no in $E_2$.
\newline\newline
Two events E and F are independent if and only if 
\begin{center}
$Pr(E\cap F) = Pr(E) \cdot Pr(F).$
\end{center}
\newpage
The conditional probability that event E occurs given that event F occurs is
\begin{center}
$Pr(E|F) = \tfrac{Pr(E\cap F)}{Pr(F)}$
\newline
\newline
\emph{The conditional probability is well-defined only if} Pr(F) $>$ 0.
\end{center}
\section{Probability theory basics}
\section{Distributed algorithm to check equality of strings}
\section{Algorithm to verify polynomial equivalence}
\section{Algorithm to verify matrix products}

\chapter{Random variables and expectations}
\section{Rnd. vars}
\section{Expectations}
\section{The Bernoulli rnd var}
\section{The Binomail rnd var}
\section{The Geometric rnd var}
\section{The coupons collector problem (I)}
\section{1/2-approximation algorithm for MaxCut}
\section{7/8-approximation algorithm for Max3Sat}
\section{Quicksort}

\chapter{Moments and deviations}
\section{Markov's inequality}
\section{Variance and moments}
\section{Chebyshev's inequality}
\section{Coupons collector problem (II)}
\section{Randomized alg for the median}

\chapter{Chernoff bounds}
\section{Chernoff bounds}
\section{Random geometric graphs}
\section{Concentration of Quicksort}

\chapter{Balls and bins}
\section{Birthday paradox}
\section{Bucket sort}
\section{Poisson distribution} 
\section{Poisson approximation}
\section{Hashing}

\chapter{Markov chains}
\section{Definitions and basic properties}
\section{Stationary distributions}
\section{Random walks}
\section{Alg. for 2-sat}

\chapter{Applications}
\section{Perfect dynamic hashing}
\section{Cuckoo hashing}
\section{Skip lists}
\section{Skip nets}
\section{Primality testing}
\section{Closest pair of points}
\section{Minimum enclsing disk}
\section{Pattern matching}
\section{Blum filters}
\section{Packet routing} 
\section{Heuristics}
\section{Minimum cut}


\nocite{*}

\newpage
\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}
